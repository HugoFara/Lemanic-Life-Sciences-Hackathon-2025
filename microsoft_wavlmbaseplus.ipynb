{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b6c7c4",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Let's create a model first, with some vocab.\n",
    "The output is a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f115131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "515.38s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in ./.venv/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.5.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.venv/lib/python3.12/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.12/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.venv/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./.venv/lib/python3.12/site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.venv/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa numpy soundfile torch torchaudio datasets transformers matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d917c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2 [00:00<?, ? examples/s]/home/hugo/Documents/dev/asr/Lemanic-Life-Sciences-Hackathon-2025/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00,  3.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities shape: (2, 292, 50)\n",
      "Recognized phoneme sequence: noɛnəmœɑdby<blank>ɑmlɹzdfɒz[UNK]jɑʁoɹʃɛlytɒploləzd[PAD]t[UNK]̃[PAD]r[PAD]əfɐɹɜzerɛzɛtyozl[PAD]v<blank>[PAD]ɐldɛzd[UNK]ʁ<blank>ɛ[PAD]ɲɒɐʌɔl)søsɜy)zis[PAD]njbpdoɲ[UNK]jl<blank>lpɛɐtbdsfjrt[UNK]lɜz)jlɐnjo)(ə(dɛɲz(ʁɑl[PAD]ʃifɐɹɛ[PAD]zibzryɛd)ɡodɹ[PAD]ɹ̃[PAD]ɐɑə\n",
      "Transcript for reference: MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import WavLMModel, AutoFeatureExtractor\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "# PhonemeRecognizer: WavLM + CTC for phoneme speech recognition\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "# Load vocab from file\n",
    "with open(\"phoneme_tokenizer/vocab.json\") as vocab_file:\n",
    "    vocab = json.load(vocab_file)\n",
    "\n",
    "# IT + FR phonemes + blank\n",
    "VOCAB = {\n",
    "  \"0\": \"ʒ\",\n",
    "  \"1\": \"ɹ\",\n",
    "  \"2\": \"j\",\n",
    "  \"3\": \"d\",\n",
    "  \"4\": \"ɲ\",\n",
    "  \"5\": \"ʌ\",\n",
    "  \"6\": \"[UNK]\",\n",
    "  \"7\": \"ɒ\",\n",
    "  \"8\": \"ɐ\",\n",
    "  \"9\": \"ʃ\",\n",
    "  \"10\": \"ɔ\",\n",
    "  \"11\": \"f\",\n",
    "  \"12\": \"ø\",\n",
    "  \"13\": \"z\",\n",
    "  \"14\": \"ŋ\",\n",
    "  \"15\": \"i\",\n",
    "  \"16\": \"u\",\n",
    "  \"17\": \"̃\",\n",
    "  \"18\": \"o\",\n",
    "  \"19\": \"œ\",\n",
    "  \"20\": \"a\",\n",
    "  \"21\": \"(\",\n",
    "  \"22\": \"ə\",\n",
    "  \"23\": \"ɜ\",\n",
    "  \"24\": \"ɾ\",\n",
    "  \"25\": \"ː\",\n",
    "  \"26\": \"̪\",\n",
    "  \"27\": \"e\",\n",
    "  \"28\": \"b\",\n",
    "  \"29\": \"ʁ\",\n",
    "  \"30\": \"w\",\n",
    "  \"31\": \"n\",\n",
    "  \"32\": \"p\",\n",
    "  \"33\": \"y\",\n",
    "  \"34\": \"ɡ\",\n",
    "  \"35\": \"ɪ\",\n",
    "  \"36\": \"r\",\n",
    "  \"37\": \"v\",\n",
    "  \"38\": \"t\",\n",
    "  \"39\": \")\",\n",
    "  \"40\": \"m\",\n",
    "  \"41\": \"k\",\n",
    "  \"42\": \"ʊ\",\n",
    "  \"43\": \"ʎ\",\n",
    "  \"44\": \"ɑ\",\n",
    "  \"45\": \"s\",\n",
    "  \"46\": \"l\",\n",
    "  \"47\": \"[PAD]\",\n",
    "  \"48\": \"ɛ\",\n",
    "  \"49\": '<blank>' # blank token for CTC\n",
    "}\n",
    "PHONEME_DICT = {v: int(k) for k, v in VOCAB.items()}\n",
    "\n",
    "NUM_PHONEMES = len(PHONEME_DICT)\n",
    "\n",
    "class PhonemeRecognizer(nn.Module):\n",
    "    def __init__(self, wavlm_model, num_phonemes=NUM_PHONEMES):\n",
    "        super().__init__()\n",
    "        self.wavlm = wavlm_model\n",
    "\n",
    "        # Get the hidden size from the WavLM model\n",
    "        hidden_size = self.wavlm.config.hidden_size\n",
    "\n",
    "        # Add a dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Linear layer to map from WavLM hidden states to phoneme classes (including blank)\n",
    "        self.phoneme_classifier = nn.Linear(hidden_size, num_phonemes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Get WavLM embeddings\n",
    "        outputs = self.wavlm(**inputs)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # Apply dropout\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # Apply the linear layer to get logits for each time step\n",
    "        logits = self.phoneme_classifier(hidden_states)\n",
    "\n",
    "        # Apply log softmax for CTC loss\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        return log_probs\n",
    "    \n",
    "    def classify_to_phonemes(self, log_probs):\n",
    "        # Simple greedy decoding (for demonstration)\n",
    "        # In a real system, you would use beam search with ctcdecode\n",
    "        predictions = torch.argmax(log_probs, dim=-1).cpu().numpy()\n",
    "\n",
    "        # Convert to phoneme sequences with CTC decoding rules (merge repeats, remove blanks)\n",
    "        phoneme_sequences = []\n",
    "        for pred_seq in predictions:\n",
    "            seq = []\n",
    "            prev = -1\n",
    "            for p in pred_seq:\n",
    "                # Skip blanks (index 0) and repeated phonemes (CTC rules)\n",
    "                if p != 0 and p != prev:\n",
    "                    # Convert index back to phoneme\n",
    "                    phoneme = list(PHONEME_DICT.keys())[list(PHONEME_DICT.values()).index(p)]\n",
    "                    seq.append(phoneme)\n",
    "                prev = p\n",
    "            phoneme_sequences.append(seq)\n",
    "\n",
    "        return phoneme_sequences\n",
    "\n",
    "\n",
    "    def recognize(self, inputs, beam_width=100):\n",
    "        \"\"\"Perform phoneme recognition without beam search decoding\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to get log probabilities\n",
    "            log_probs = self(inputs)\n",
    "\n",
    "            return self.classify_to_phonemes(log_probs)\n",
    "\n",
    "    def tokenize(self, char_list):\n",
    "        \"\"\"Go from a list of characters to a list of indices.\"\"\"\n",
    "        return torch.tensor([PHONEME_DICT[x] for x in char_list])\n",
    "    \n",
    "    def get_embedding(self, char_list):\n",
    "        tokens = self.tokenize(char_list)\n",
    "        out_tensor = torch.zeros((len(tokens), len(PHONEME_DICT)))\n",
    "        for i, token_id in enumerate(tokens):\n",
    "            out_tensor[i, token_id] = 1\n",
    "        return out_tensor\n",
    "\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "# Method A: Using the PhonemeRecognizer for speech-to-phoneme ASR\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "# 1. Load the feature extractor and model\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/wavlm-base-plus\")\n",
    "wavlm_model = WavLMModel.from_pretrained(\"microsoft/wavlm-base-plus\")\n",
    "\n",
    "# Create the phoneme recognizer with the WavLM model\n",
    "phoneme_recognizer = PhonemeRecognizer(wavlm_model)\n",
    "phoneme_recognizer.eval()  # disable dropout, etc.\n",
    "\n",
    "# 2. Load an example audio file (here using a small demo from `datasets`)\n",
    "#    The `audio[\"array\"]` is a NumPy array of floats; sampling_rate is an int.\n",
    "ds = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "audio_sample = ds[0][\"audio\"][\"array\"]\n",
    "sr = ds[0][\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "def get_audio_features(batch):\n",
    "    # 3. Preprocess (pad/truncate + batch‐dim)\n",
    "    for data_row in batch:\n",
    "        if data_row[\"sampling_rate\"] != 16000:\n",
    "            raise NotImplementedError(\n",
    "                f\"No sampling rate can be different from 16000, is {data_row[\"sampling_rate\"]}\"\n",
    "            )\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        [data_row[\"array\"] for data_row in batch],\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",        # => PyTorch tensors\n",
    "        padding=True,               # pad to longest in batch\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def run_inference(batch, model):\n",
    "    \"\"\"Return log probs and most likely phonemes.\"\"\"\n",
    "    inputs = get_audio_features(batch[\"audio\"])\n",
    "\n",
    "    # 4. Inference for phoneme recognition\n",
    "    with torch.no_grad():\n",
    "        # Get phoneme log probabilities\n",
    "        log_probs = model(inputs)\n",
    "\n",
    "        # Recognize phoneme sequence\n",
    "        phoneme_sequences = model.recognize(inputs)\n",
    "\n",
    "    return {\"log_probs\": log_probs, \"phonemes\": phoneme_sequences}\n",
    "\n",
    "predicted = ds.select(range(2)).map(\n",
    "    lambda data_row: run_inference(data_row, phoneme_recognizer),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(\"Log probabilities shape:\", np.shape(predicted[\"log_probs\"]))  # (batch_size, seq_len, num_phonemes)\n",
    "print(\"Recognized phoneme sequence:\", \"\".join(predicted[\"phonemes\"][0]))\n",
    "print(\"Transcript for reference:\", ds[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5207f7",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's load our data in a Hugging Face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65d3d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4127911e9bc14d59904d73acf74833aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03239afe563949a5a8dfac61fb0f876a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6048f5ad94934d448a3bec3272b9f249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b791c0828140ddac310c8787ff2432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_name', 'audio', 'target_phonemes1', 'target_phonemes2'],\n",
      "    num_rows: 5507\n",
      "})\n",
      "{'path': 'Hackathon_ASR/2_Audiofiles/Phoneme_Deletion_FR_T1/3101_edugame2023_1c148def3c254026adc7a7fdc3edc6f6_2249c5f2f75d4b089bee1f36e1a7aef2.wav', 'array': array([1.97946756e-05, 3.31596239e-05, 2.90264506e-05, ...,\n",
      "       1.05573982e-03, 2.05589482e-03, 0.00000000e+00], shape=(66317,)), 'sampling_rate': 16000}\n",
      "['ɑ', '̃', '[PAD]', 'n', 'a', 'ʒ']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import datasets\n",
    "\n",
    "# 1. Location of your CSV\n",
    "language = (\"fr\", \"it\")[0]\n",
    "audio_files_path = \"Hackathon_ASR/2_Audiofiles/\" + {\n",
    "    \"fr\": \"Phoneme_Deletion_FR\",\n",
    "    \"it\": \"Decoding_IT\"\n",
    "}[language] + \"_T1/\"\n",
    "dataset_path = f\"datasets/phonemized_{language}.csv\"\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"{dataset_path} does not exist and should be regenerated!\")\n",
    "\n",
    "\n",
    "# 2. Define initial features: audio paths as plain strings, phonemes as plain strings\n",
    "features = datasets.Features({\n",
    "    \"file_name\": datasets.Value(\"string\"),\n",
    "    \"phonemes_coder1\": datasets.Value(\"string\"),\n",
    "    \"phonemes_coder2\": datasets.Value(\"string\")\n",
    "})\n",
    "\n",
    "# 3. Load the CSV into a DatasetDict (default split is 'train')\n",
    "dataset = datasets.load_dataset(\"csv\", data_files=dataset_path, features=features, split=\"train\")\n",
    "\n",
    "# 4. Rename the audio-path column to 'audio' (required by Audio feature)\n",
    "dataset = dataset.map(lambda data_row: {\"audio\": audio_files_path + data_row[\"file_name\"]})\n",
    "\n",
    "# 5. Cast 'audio' to the Audio type (will load the file when you access it)\n",
    "dataset = dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16_000))\n",
    "\n",
    "# 6. Map + split phoneme strings into lists\n",
    "def split_in_bracket(string):\n",
    "    output = []\n",
    "    in_brackets = False\n",
    "    if string is None:\n",
    "        return output\n",
    "    for char in string:\n",
    "        if in_brackets:\n",
    "            output[-1] += char\n",
    "        else:\n",
    "            output.append(char)\n",
    "\n",
    "        if char == '[':\n",
    "            in_brackets = True\n",
    "        elif char == ']':\n",
    "            in_brackets = False\n",
    "    return output\n",
    "\n",
    "def split_phonemes(data_row):\n",
    "    \"\"\"Split each phoneme into a list.\"\"\"\n",
    "    data_row[\"target_phonemes1\"] = split_in_bracket(data_row[\"phonemes_coder1\"])\n",
    "    data_row[\"target_phonemes2\"] = split_in_bracket(data_row[\"phonemes_coder2\"])\n",
    "    return data_row\n",
    "\n",
    "\n",
    "dataset = dataset.map(split_phonemes, remove_columns=[\"phonemes_coder1\", \"phonemes_coder2\"])\n",
    "\n",
    "# 7. Cast the phoneme_sequence column to a Sequence of strings\n",
    "dataset = dataset.cast_column(\n",
    "    \"target_phonemes1\",\n",
    "    datasets.Sequence(feature=datasets.Value(\"string\"))\n",
    ").cast_column(\n",
    "    \"target_phonemes2\",\n",
    "    datasets.Sequence(feature=datasets.Value(\"string\"))\n",
    ")\n",
    "\n",
    "# Now 'dataset' has:\n",
    "#   - dataset[i][\"audio\"] → { \"array\": np.ndarray, \"sampling_rate\": 16000 }\n",
    "#   - dataset[i][\"target_phonemes1\"] → list of strings\n",
    "print(dataset)\n",
    "print(dataset[0][\"audio\"])\n",
    "print(dataset[0][\"target_phonemes1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf53be",
   "metadata": {},
   "source": [
    "## Putting stuff together\n",
    "\n",
    "Now we run the model on our in-house dataset.\n",
    "We will extract the features so that it is easier to work with latter on.\n",
    "For this version we don't train the model, only a fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0ab1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['target_phonemes', 'features'],\n",
       "    num_rows: 932\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASETS_DIR = \"datasets\"\n",
    "dataset_path = f\"{DATASETS_DIR}/features\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    features_dataset = datasets.load_from_disk(dataset_path)\n",
    "else:\n",
    "    wavlm_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features_dataset = dataset.map(\n",
    "            lambda batch: {\n",
    "                \"features\": wavlm_model(**get_audio_features(batch[\"audio\"])).last_hidden_state\n",
    "            },\n",
    "            batched=True,\n",
    "            remove_columns=[\"audio\"],\n",
    "            batch_size=15\n",
    "        )\n",
    "\n",
    "    features_dataset.save_to_disk(dataset_path)\n",
    "features_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690dea4",
   "metadata": {},
   "source": [
    "## Defining a new linear layer\n",
    "\n",
    "As a speed-up, we simply create a linear layer to map from the extracted features to the phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dfda0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PhonemeMapper(nn.Module):\n",
    "    def __init__(self, features_size, num_phonemes=NUM_PHONEMES):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add a dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Linear layer to map from WavLM hidden states to phoneme classes (including blank)\n",
    "        self.phoneme_classifier = nn.Linear(features_size, num_phonemes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Apply dropout\n",
    "        hidden_states = self.dropout(inputs)\n",
    "\n",
    "        # Apply the linear layer to get logits for each time step\n",
    "        logits = self.phoneme_classifier(hidden_states)\n",
    "\n",
    "        # Apply log softmax for CTC loss\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        return log_probs\n",
    "    \n",
    "    def classify_to_phonemes(self, log_probs):\n",
    "        # Simple greedy decoding (for demonstration)\n",
    "        # In a real system, you would use beam search with ctcdecode\n",
    "        predictions = torch.argmax(log_probs, dim=-1).cpu().numpy()\n",
    "\n",
    "        # Convert to phoneme sequences with CTC decoding rules (merge repeats, remove blanks)\n",
    "        phoneme_sequences = []\n",
    "        for pred_seq in predictions:\n",
    "            seq = []\n",
    "            prev = -1\n",
    "            for p in pred_seq:\n",
    "                # Skip blanks (index 0) and repeated phonemes (CTC rules)\n",
    "                if p != 0 and p != prev:\n",
    "                    # Convert index back to phoneme\n",
    "                    phoneme = list(PHONEME_DICT.keys())[list(PHONEME_DICT.values()).index(p)]\n",
    "                    seq.append(phoneme)\n",
    "                prev = p\n",
    "            phoneme_sequences.append(seq)\n",
    "\n",
    "        return phoneme_sequences\n",
    "    \n",
    "linear_mapper = PhonemeMapper(wavlm_model.config.hidden_size, NUM_PHONEMES)\n",
    "\n",
    "wavlm_model.config.hidden_size, NUM_PHONEMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc4765",
   "metadata": {},
   "source": [
    "## Model fine-tuning\n",
    "\n",
    "Now that the linear layer is ready, we can simply train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79bfb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 66.48863220214844\n",
      "Epoch 0, Loss: 208.7238006591797\n",
      "Epoch 0, Loss: 208.34446716308594\n",
      "Epoch 0, Loss: 76.80451965332031\n",
      "Epoch 0, Loss: 418.4235534667969\n",
      "Epoch 0, Loss: 199.16065979003906\n",
      "Epoch 0, Loss: 726.5738525390625\n",
      "Epoch 0, Loss: 96.77622985839844\n",
      "Epoch 0, Loss: 87.0539321899414\n",
      "Epoch 0, Loss: 91.49258422851562\n",
      "Epoch 0, Loss: 425.8016357421875\n",
      "Epoch 0, Loss: 65.01165008544922\n",
      "Epoch 0, Loss: 104.83248901367188\n",
      "Epoch 0, Loss: 67.78790283203125\n",
      "Epoch 0, Loss: 696.1923828125\n",
      "Epoch 0, Loss: 88.33753967285156\n",
      "Epoch 0, Loss: 83.66516876220703\n",
      "Epoch 0, Loss: 1007.812255859375\n",
      "Epoch 0, Loss: 82.21784210205078\n",
      "Epoch 0, Loss: 408.822265625\n",
      "Epoch 0, Loss: 410.20294189453125\n",
      "Epoch 0, Loss: 96.42254638671875\n",
      "Epoch 0, Loss: 101.1806869506836\n",
      "Epoch 0, Loss: 202.9730682373047\n",
      "Epoch 0, Loss: 399.52813720703125\n",
      "Epoch 0, Loss: 74.95931243896484\n",
      "Epoch 0, Loss: 140.1988525390625\n",
      "Epoch 0, Loss: 150.25926208496094\n",
      "Epoch 0, Loss: 82.55825805664062\n",
      "Epoch 0, Loss: 132.5712432861328\n",
      "Epoch 0, Loss: 406.77935791015625\n",
      "Epoch 0, Loss: 80.7060546875\n",
      "Epoch 0, Loss: 90.67864990234375\n",
      "Epoch 0, Loss: 72.1282958984375\n",
      "Epoch 0, Loss: 87.95555877685547\n",
      "Epoch 0, Loss: 73.2546615600586\n",
      "Epoch 0, Loss: 738.881591796875\n",
      "Epoch 0, Loss: 75.47376251220703\n",
      "Epoch 0, Loss: 430.7385559082031\n",
      "Epoch 0, Loss: 71.56787109375\n",
      "Epoch 0, Loss: 75.32752990722656\n",
      "Epoch 0, Loss: 78.85603332519531\n",
      "Epoch 0, Loss: 80.0233383178711\n",
      "Epoch 0, Loss: 84.4547119140625\n",
      "Epoch 0, Loss: 386.13275146484375\n",
      "Epoch 0, Loss: 66.99555969238281\n",
      "Epoch 0, Loss: 88.97126770019531\n",
      "Epoch 0, Loss: 402.66650390625\n",
      "Epoch 0, Loss: 71.27188110351562\n",
      "Epoch 0, Loss: 749.658203125\n",
      "Epoch 0, Loss: 433.30181884765625\n",
      "Epoch 0, Loss: 66.2596435546875\n",
      "Epoch 0, Loss: 65.21269989013672\n",
      "Epoch 0, Loss: 96.73197937011719\n",
      "Epoch 0, Loss: 70.41249084472656\n",
      "Epoch 0, Loss: 86.04389953613281\n",
      "Epoch 0, Loss: 75.5184097290039\n",
      "Epoch 0, Loss: 76.5353012084961\n",
      "Epoch 0, Loss: 62.39017105102539\n",
      "Epoch 0, Loss: 132.54522705078125\n",
      "Epoch 0, Loss: 407.2109375\n",
      "Epoch 0, Loss: 712.741455078125\n",
      "Epoch 0, Loss: 72.7804183959961\n",
      "Epoch 0, Loss: 66.03003692626953\n",
      "Epoch 0, Loss: 91.50175476074219\n",
      "Epoch 0, Loss: 119.99696350097656\n",
      "Epoch 0, Loss: 73.87765502929688\n",
      "Epoch 0, Loss: 414.9988708496094\n",
      "Epoch 0, Loss: 65.95734405517578\n",
      "Epoch 0, Loss: 392.8249816894531\n",
      "Epoch 0, Loss: 394.71478271484375\n",
      "Epoch 0, Loss: 75.19029998779297\n",
      "Epoch 0, Loss: 176.3377227783203\n",
      "Epoch 0, Loss: 388.42840576171875\n",
      "Epoch 0, Loss: 403.8798828125\n",
      "Epoch 0, Loss: 80.17109680175781\n",
      "Epoch 0, Loss: 71.80699920654297\n",
      "Epoch 0, Loss: 390.70245361328125\n",
      "Epoch 0, Loss: 79.37171173095703\n",
      "Epoch 0, Loss: 434.0771179199219\n",
      "Epoch 0, Loss: 73.98843383789062\n",
      "Epoch 0, Loss: 68.5287094116211\n",
      "Epoch 0, Loss: 110.57451629638672\n",
      "Epoch 0, Loss: 394.2743225097656\n",
      "Epoch 0, Loss: 69.93611145019531\n",
      "Epoch 0, Loss: 1013.1124267578125\n",
      "Epoch 0, Loss: 71.09221649169922\n",
      "Epoch 0, Loss: 98.02141571044922\n",
      "Epoch 0, Loss: 64.25180053710938\n",
      "Epoch 0, Loss: 69.99890899658203\n",
      "Epoch 0, Loss: 407.3470458984375\n",
      "Epoch 0, Loss: 84.50686645507812\n",
      "Epoch 0, Loss: 70.05428314208984\n",
      "Epoch 0, Loss: 64.87479400634766\n",
      "Epoch 0, Loss: 130.86395263671875\n",
      "Epoch 0, Loss: 192.41249084472656\n",
      "Epoch 0, Loss: 100.03817749023438\n",
      "Epoch 0, Loss: 551.675537109375\n",
      "Epoch 0, Loss: 72.69377899169922\n",
      "Epoch 0, Loss: 420.6510314941406\n",
      "Epoch 0, Loss: 68.25151062011719\n",
      "Epoch 0, Loss: 371.0647888183594\n",
      "Epoch 0, Loss: 75.92815399169922\n",
      "Epoch 0, Loss: 65.8893051147461\n",
      "Epoch 0, Loss: 67.63361358642578\n",
      "Epoch 0, Loss: 163.26278686523438\n",
      "Epoch 0, Loss: 104.73442840576172\n",
      "Epoch 0, Loss: 64.0573959350586\n",
      "Epoch 0, Loss: 69.43474578857422\n",
      "Epoch 0, Loss: 109.17535400390625\n",
      "Epoch 0, Loss: 67.59335327148438\n",
      "Epoch 0, Loss: 100.08258056640625\n",
      "Epoch 0, Loss: 79.55790710449219\n",
      "Epoch 0, Loss: 84.8448715209961\n",
      "Epoch 0, Loss: 209.6958465576172\n",
      "Epoch 0, Loss: 77.03430938720703\n",
      "Epoch 0, Loss: 4735.91748046875\n",
      "Epoch 1, Loss: 407.2789001464844\n",
      "Epoch 1, Loss: 70.46294403076172\n",
      "Epoch 1, Loss: 137.1544189453125\n",
      "Epoch 1, Loss: 405.3669738769531\n",
      "Epoch 1, Loss: 95.62545776367188\n",
      "Epoch 1, Loss: 77.79642486572266\n",
      "Epoch 1, Loss: 76.04768371582031\n",
      "Epoch 1, Loss: 90.02603149414062\n",
      "Epoch 1, Loss: 117.67411041259766\n",
      "Epoch 1, Loss: 66.68309020996094\n",
      "Epoch 1, Loss: 94.61136627197266\n",
      "Epoch 1, Loss: 94.1761245727539\n",
      "Epoch 1, Loss: 420.6838684082031\n",
      "Epoch 1, Loss: 81.46749114990234\n",
      "Epoch 1, Loss: 62.91332244873047\n",
      "Epoch 1, Loss: 66.99288940429688\n",
      "Epoch 1, Loss: 71.59477996826172\n",
      "Epoch 1, Loss: 406.0115051269531\n",
      "Epoch 1, Loss: 102.87850189208984\n",
      "Epoch 1, Loss: 68.917724609375\n",
      "Epoch 1, Loss: 410.9893798828125\n",
      "Epoch 1, Loss: 408.9411315917969\n",
      "Epoch 1, Loss: 104.72871398925781\n",
      "Epoch 1, Loss: 402.79705810546875\n",
      "Epoch 1, Loss: 446.252197265625\n",
      "Epoch 1, Loss: 401.6071472167969\n",
      "Epoch 1, Loss: 67.34329223632812\n",
      "Epoch 1, Loss: 75.63224792480469\n",
      "Epoch 1, Loss: 67.30681610107422\n",
      "Epoch 1, Loss: 149.27093505859375\n",
      "Epoch 1, Loss: 96.05961608886719\n",
      "Epoch 1, Loss: 61.37038040161133\n",
      "Epoch 1, Loss: 81.51808166503906\n",
      "Epoch 1, Loss: 406.23565673828125\n",
      "Epoch 1, Loss: 67.25667572021484\n",
      "Epoch 1, Loss: 143.2408447265625\n",
      "Epoch 1, Loss: 122.85554504394531\n",
      "Epoch 1, Loss: 134.6752471923828\n",
      "Epoch 1, Loss: 100.7538833618164\n",
      "Epoch 1, Loss: 69.90177917480469\n",
      "Epoch 1, Loss: 74.40823364257812\n",
      "Epoch 1, Loss: 78.3637466430664\n",
      "Epoch 1, Loss: 744.3224487304688\n",
      "Epoch 1, Loss: 74.3377685546875\n",
      "Epoch 1, Loss: 722.41015625\n",
      "Epoch 1, Loss: 133.16883850097656\n",
      "Epoch 1, Loss: 100.2166748046875\n",
      "Epoch 1, Loss: 85.32897186279297\n",
      "Epoch 1, Loss: 76.17451477050781\n",
      "Epoch 1, Loss: 142.1585235595703\n",
      "Epoch 1, Loss: 191.04661560058594\n",
      "Epoch 1, Loss: 125.34288787841797\n",
      "Epoch 1, Loss: 166.47222900390625\n",
      "Epoch 1, Loss: 414.0259704589844\n",
      "Epoch 1, Loss: 75.55204010009766\n",
      "Epoch 1, Loss: 206.06932067871094\n",
      "Epoch 1, Loss: 80.21365356445312\n",
      "Epoch 1, Loss: 662.5595092773438\n",
      "Epoch 1, Loss: 103.53308868408203\n",
      "Epoch 1, Loss: 114.67266082763672\n",
      "Epoch 1, Loss: 69.312744140625\n",
      "Epoch 1, Loss: 396.25128173828125\n",
      "Epoch 1, Loss: 703.7754516601562\n",
      "Epoch 1, Loss: 62.94778823852539\n",
      "Epoch 1, Loss: 72.20654296875\n",
      "Epoch 1, Loss: 84.49793243408203\n",
      "Epoch 1, Loss: 73.30126190185547\n",
      "Epoch 1, Loss: 73.24694061279297\n",
      "Epoch 1, Loss: 78.04470825195312\n",
      "Epoch 1, Loss: 76.94080352783203\n",
      "Epoch 1, Loss: 79.81238555908203\n",
      "Epoch 1, Loss: 59.97527313232422\n",
      "Epoch 1, Loss: 69.35787200927734\n",
      "Epoch 1, Loss: 90.99357604980469\n",
      "Epoch 1, Loss: 69.12059020996094\n",
      "Epoch 1, Loss: 467.4493103027344\n",
      "Epoch 1, Loss: 517.3370971679688\n",
      "Epoch 1, Loss: 60.43837356567383\n",
      "Epoch 1, Loss: 72.82469940185547\n",
      "Epoch 1, Loss: 401.0374755859375\n",
      "Epoch 1, Loss: 72.84366607666016\n",
      "Epoch 1, Loss: 80.4631576538086\n",
      "Epoch 1, Loss: 61.476287841796875\n",
      "Epoch 1, Loss: 376.52978515625\n",
      "Epoch 1, Loss: 65.23594665527344\n",
      "Epoch 1, Loss: 90.81022644042969\n",
      "Epoch 1, Loss: 402.19757080078125\n",
      "Epoch 1, Loss: 78.73727416992188\n",
      "Epoch 1, Loss: 75.50914001464844\n",
      "Epoch 1, Loss: 76.15238189697266\n",
      "Epoch 1, Loss: 64.50947570800781\n",
      "Epoch 1, Loss: 68.7812271118164\n",
      "Epoch 1, Loss: 169.012939453125\n",
      "Epoch 1, Loss: 73.77405548095703\n",
      "Epoch 1, Loss: 178.3737335205078\n",
      "Epoch 1, Loss: 69.38939666748047\n",
      "Epoch 1, Loss: 86.63772583007812\n",
      "Epoch 1, Loss: 484.3355712890625\n",
      "Epoch 1, Loss: 416.8018798828125\n",
      "Epoch 1, Loss: 392.7102355957031\n",
      "Epoch 1, Loss: 71.57101440429688\n",
      "Epoch 1, Loss: 81.3766860961914\n",
      "Epoch 1, Loss: 75.56963348388672\n",
      "Epoch 1, Loss: 87.02128601074219\n",
      "Epoch 1, Loss: 204.77218627929688\n",
      "Epoch 1, Loss: 93.3823471069336\n",
      "Epoch 1, Loss: 172.94541931152344\n",
      "Epoch 1, Loss: 71.67523193359375\n",
      "Epoch 1, Loss: 77.30402374267578\n",
      "Epoch 1, Loss: 409.33197021484375\n",
      "Epoch 1, Loss: 83.1177978515625\n",
      "Epoch 1, Loss: 159.72056579589844\n",
      "Epoch 1, Loss: 78.74683380126953\n",
      "Epoch 1, Loss: 82.3214111328125\n",
      "Epoch 1, Loss: 77.87153625488281\n",
      "Epoch 1, Loss: 200.40017700195312\n",
      "Epoch 1, Loss: 4705.12646484375\n",
      "Epoch 2, Loss: 80.74854278564453\n",
      "Epoch 2, Loss: 399.32720947265625\n",
      "Epoch 2, Loss: 84.29564666748047\n",
      "Epoch 2, Loss: 81.79094696044922\n",
      "Epoch 2, Loss: 64.60731506347656\n",
      "Epoch 2, Loss: 202.62417602539062\n",
      "Epoch 2, Loss: 75.90817260742188\n",
      "Epoch 2, Loss: 405.824462890625\n",
      "Epoch 2, Loss: 76.53485107421875\n",
      "Epoch 2, Loss: 101.71437072753906\n",
      "Epoch 2, Loss: 59.40660095214844\n",
      "Epoch 2, Loss: 151.4567413330078\n",
      "Epoch 2, Loss: 78.31983184814453\n",
      "Epoch 2, Loss: 78.1606674194336\n",
      "Epoch 2, Loss: 729.7677001953125\n",
      "Epoch 2, Loss: 405.8481750488281\n",
      "Epoch 2, Loss: 70.25070190429688\n",
      "Epoch 2, Loss: 88.1124038696289\n",
      "Epoch 2, Loss: 77.61469268798828\n",
      "Epoch 2, Loss: 76.97097778320312\n",
      "Epoch 2, Loss: 408.5830078125\n",
      "Epoch 2, Loss: 83.83891296386719\n",
      "Epoch 2, Loss: 405.7237854003906\n",
      "Epoch 2, Loss: 80.76972198486328\n",
      "Epoch 2, Loss: 78.63206481933594\n",
      "Epoch 2, Loss: 95.89349365234375\n",
      "Epoch 2, Loss: 351.4621276855469\n",
      "Epoch 2, Loss: 62.236209869384766\n",
      "Epoch 2, Loss: 89.0653076171875\n",
      "Epoch 2, Loss: 435.3696594238281\n",
      "Epoch 2, Loss: 69.54859924316406\n",
      "Epoch 2, Loss: 64.25434875488281\n",
      "Epoch 2, Loss: 397.5152893066406\n",
      "Epoch 2, Loss: 77.47378540039062\n",
      "Epoch 2, Loss: 72.69009399414062\n",
      "Epoch 2, Loss: 75.42615509033203\n",
      "Epoch 2, Loss: 703.185791015625\n",
      "Epoch 2, Loss: 73.14424133300781\n",
      "Epoch 2, Loss: 92.81863403320312\n",
      "Epoch 2, Loss: 396.2597351074219\n",
      "Epoch 2, Loss: 159.4693603515625\n",
      "Epoch 2, Loss: 96.56303405761719\n",
      "Epoch 2, Loss: 400.1726989746094\n",
      "Epoch 2, Loss: 208.97169494628906\n",
      "Epoch 2, Loss: 109.58751678466797\n",
      "Epoch 2, Loss: 68.85318756103516\n",
      "Epoch 2, Loss: 78.70491790771484\n",
      "Epoch 2, Loss: 373.0780029296875\n",
      "Epoch 2, Loss: 363.809326171875\n",
      "Epoch 2, Loss: 86.51454162597656\n",
      "Epoch 2, Loss: 75.74372863769531\n",
      "Epoch 2, Loss: 73.05885314941406\n",
      "Epoch 2, Loss: 400.0520935058594\n",
      "Epoch 2, Loss: 396.2145690917969\n",
      "Epoch 2, Loss: 74.51654815673828\n",
      "Epoch 2, Loss: 496.1860046386719\n",
      "Epoch 2, Loss: 106.41206359863281\n",
      "Epoch 2, Loss: 86.5172119140625\n",
      "Epoch 2, Loss: 85.84537506103516\n",
      "Epoch 2, Loss: 89.87103271484375\n",
      "Epoch 2, Loss: 67.79997253417969\n",
      "Epoch 2, Loss: 63.30241394042969\n",
      "Epoch 2, Loss: 146.57093811035156\n",
      "Epoch 2, Loss: 110.03485870361328\n",
      "Epoch 2, Loss: 68.77040100097656\n",
      "Epoch 2, Loss: 378.9613037109375\n",
      "Epoch 2, Loss: 77.84387969970703\n",
      "Epoch 2, Loss: 103.07714080810547\n",
      "Epoch 2, Loss: 71.74574279785156\n",
      "Epoch 2, Loss: 64.06607818603516\n",
      "Epoch 2, Loss: 569.22021484375\n",
      "Epoch 2, Loss: 70.50794219970703\n",
      "Epoch 2, Loss: 61.04865264892578\n",
      "Epoch 2, Loss: 454.30987548828125\n",
      "Epoch 2, Loss: 399.120361328125\n",
      "Epoch 2, Loss: 95.8382339477539\n",
      "Epoch 2, Loss: 61.039459228515625\n",
      "Epoch 2, Loss: 486.91619873046875\n",
      "Epoch 2, Loss: 67.69490051269531\n",
      "Epoch 2, Loss: 92.11026763916016\n",
      "Epoch 2, Loss: 112.86371612548828\n",
      "Epoch 2, Loss: 70.78380584716797\n",
      "Epoch 2, Loss: 104.90277862548828\n",
      "Epoch 2, Loss: 70.66497039794922\n",
      "Epoch 2, Loss: 401.44256591796875\n",
      "Epoch 2, Loss: 407.1542053222656\n",
      "Epoch 2, Loss: 86.30618286132812\n",
      "Epoch 2, Loss: 72.91691589355469\n",
      "Epoch 2, Loss: 126.87104797363281\n",
      "Epoch 2, Loss: 116.29362487792969\n",
      "Epoch 2, Loss: 170.29803466796875\n",
      "Epoch 2, Loss: 76.226806640625\n",
      "Epoch 2, Loss: 68.14916229248047\n",
      "Epoch 2, Loss: 74.70696258544922\n",
      "Epoch 2, Loss: 368.0446472167969\n",
      "Epoch 2, Loss: 68.53428649902344\n",
      "Epoch 2, Loss: 377.20172119140625\n",
      "Epoch 2, Loss: 414.48773193359375\n",
      "Epoch 2, Loss: 76.46406555175781\n",
      "Epoch 2, Loss: 80.08714294433594\n",
      "Epoch 2, Loss: 123.32646179199219\n",
      "Epoch 2, Loss: 382.9150695800781\n",
      "Epoch 2, Loss: 80.38549041748047\n",
      "Epoch 2, Loss: 404.2626647949219\n",
      "Epoch 2, Loss: 79.5522232055664\n",
      "Epoch 2, Loss: 378.8641662597656\n",
      "Epoch 2, Loss: 70.88973236083984\n",
      "Epoch 2, Loss: 436.0199890136719\n",
      "Epoch 2, Loss: 81.76377868652344\n",
      "Epoch 2, Loss: 72.88371276855469\n",
      "Epoch 2, Loss: 430.5930480957031\n",
      "Epoch 2, Loss: 81.88703918457031\n",
      "Epoch 2, Loss: 96.10597229003906\n",
      "Epoch 2, Loss: 73.2666015625\n",
      "Epoch 2, Loss: 116.73031616210938\n",
      "Epoch 2, Loss: 92.64253997802734\n",
      "Epoch 2, Loss: 4716.24267578125\n",
      "Epoch 3, Loss: 724.9127197265625\n",
      "Epoch 3, Loss: 382.2374267578125\n",
      "Epoch 3, Loss: 122.8084945678711\n",
      "Epoch 3, Loss: 386.58636474609375\n",
      "Epoch 3, Loss: 397.5617370605469\n",
      "Epoch 3, Loss: 111.01649475097656\n",
      "Epoch 3, Loss: 65.81721496582031\n",
      "Epoch 3, Loss: 124.7673110961914\n",
      "Epoch 3, Loss: 74.39300537109375\n",
      "Epoch 3, Loss: 221.75161743164062\n",
      "Epoch 3, Loss: 75.92831420898438\n",
      "Epoch 3, Loss: 76.9405746459961\n",
      "Epoch 3, Loss: 70.80561828613281\n",
      "Epoch 3, Loss: 68.00334930419922\n",
      "Epoch 3, Loss: 85.96261596679688\n",
      "Epoch 3, Loss: 130.69906616210938\n",
      "Epoch 3, Loss: 202.03578186035156\n",
      "Epoch 3, Loss: 456.4677734375\n",
      "Epoch 3, Loss: 406.6972351074219\n",
      "Epoch 3, Loss: 72.94122314453125\n",
      "Epoch 3, Loss: 89.19414520263672\n",
      "Epoch 3, Loss: 95.17744445800781\n",
      "Epoch 3, Loss: 67.23492431640625\n",
      "Epoch 3, Loss: 83.06373596191406\n",
      "Epoch 3, Loss: 59.363426208496094\n",
      "Epoch 3, Loss: 690.4295654296875\n",
      "Epoch 3, Loss: 68.68646240234375\n",
      "Epoch 3, Loss: 69.24979400634766\n",
      "Epoch 3, Loss: 68.75193786621094\n",
      "Epoch 3, Loss: 71.16109466552734\n",
      "Epoch 3, Loss: 370.9850158691406\n",
      "Epoch 3, Loss: 75.81949615478516\n",
      "Epoch 3, Loss: 394.7549133300781\n",
      "Epoch 3, Loss: 217.37364196777344\n",
      "Epoch 3, Loss: 145.1868896484375\n",
      "Epoch 3, Loss: 371.65374755859375\n",
      "Epoch 3, Loss: 68.08601379394531\n",
      "Epoch 3, Loss: 191.5078125\n",
      "Epoch 3, Loss: 67.67305755615234\n",
      "Epoch 3, Loss: 368.4481201171875\n",
      "Epoch 3, Loss: 96.48082733154297\n",
      "Epoch 3, Loss: 395.4630126953125\n",
      "Epoch 3, Loss: 364.1904602050781\n",
      "Epoch 3, Loss: 436.836669921875\n",
      "Epoch 3, Loss: 63.163490295410156\n",
      "Epoch 3, Loss: 65.46319580078125\n",
      "Epoch 3, Loss: 88.72209930419922\n",
      "Epoch 3, Loss: 420.4958801269531\n",
      "Epoch 3, Loss: 65.71825408935547\n",
      "Epoch 3, Loss: 76.37983703613281\n",
      "Epoch 3, Loss: 100.59874725341797\n",
      "Epoch 3, Loss: 73.6954574584961\n",
      "Epoch 3, Loss: 71.06954956054688\n",
      "Epoch 3, Loss: 394.50341796875\n",
      "Epoch 3, Loss: 403.5959777832031\n",
      "Epoch 3, Loss: 398.0035705566406\n",
      "Epoch 3, Loss: 72.60228729248047\n",
      "Epoch 3, Loss: 373.18011474609375\n",
      "Epoch 3, Loss: 81.43830108642578\n",
      "Epoch 3, Loss: 387.7862548828125\n",
      "Epoch 3, Loss: 220.02171325683594\n",
      "Epoch 3, Loss: 69.43772888183594\n",
      "Epoch 3, Loss: 65.92415618896484\n",
      "Epoch 3, Loss: 71.91423034667969\n",
      "Epoch 3, Loss: 368.9299011230469\n",
      "Epoch 3, Loss: 75.23236846923828\n",
      "Epoch 3, Loss: 534.7138061523438\n",
      "Epoch 3, Loss: 381.3918762207031\n",
      "Epoch 3, Loss: 76.36797332763672\n",
      "Epoch 3, Loss: 85.49251556396484\n",
      "Epoch 3, Loss: 72.15665435791016\n",
      "Epoch 3, Loss: 68.21315002441406\n",
      "Epoch 3, Loss: 105.1705551147461\n",
      "Epoch 3, Loss: 129.1540069580078\n",
      "Epoch 3, Loss: 695.8997192382812\n",
      "Epoch 3, Loss: 79.86001586914062\n",
      "Epoch 3, Loss: 63.48796844482422\n",
      "Epoch 3, Loss: 138.37344360351562\n",
      "Epoch 3, Loss: 372.9378356933594\n",
      "Epoch 3, Loss: 116.29515838623047\n",
      "Epoch 3, Loss: 85.42546081542969\n",
      "Epoch 3, Loss: 82.30313110351562\n",
      "Epoch 3, Loss: 165.39300537109375\n",
      "Epoch 3, Loss: 87.2403335571289\n",
      "Epoch 3, Loss: 387.8429870605469\n",
      "Epoch 3, Loss: 378.5565185546875\n",
      "Epoch 3, Loss: 84.76234436035156\n",
      "Epoch 3, Loss: 388.83642578125\n",
      "Epoch 3, Loss: 81.06037139892578\n",
      "Epoch 3, Loss: 74.93231964111328\n",
      "Epoch 3, Loss: 69.02904510498047\n",
      "Epoch 3, Loss: 77.10509490966797\n",
      "Epoch 3, Loss: 75.70769500732422\n",
      "Epoch 3, Loss: 73.16226959228516\n",
      "Epoch 3, Loss: 85.593505859375\n",
      "Epoch 3, Loss: 353.4016418457031\n",
      "Epoch 3, Loss: 83.26913452148438\n",
      "Epoch 3, Loss: 80.43699645996094\n",
      "Epoch 3, Loss: 648.922119140625\n",
      "Epoch 3, Loss: 114.67437744140625\n",
      "Epoch 3, Loss: 70.84210205078125\n",
      "Epoch 3, Loss: 374.55926513671875\n",
      "Epoch 3, Loss: 368.1710510253906\n",
      "Epoch 3, Loss: 90.87565612792969\n",
      "Epoch 3, Loss: 414.48040771484375\n",
      "Epoch 3, Loss: 93.52318572998047\n",
      "Epoch 3, Loss: 67.99034118652344\n",
      "Epoch 3, Loss: 366.1221923828125\n",
      "Epoch 3, Loss: 393.7135314941406\n",
      "Epoch 3, Loss: 100.94036865234375\n",
      "Epoch 3, Loss: 55.55144119262695\n",
      "Epoch 3, Loss: 67.10529327392578\n",
      "Epoch 3, Loss: 88.61297607421875\n",
      "Epoch 3, Loss: 107.41654205322266\n",
      "Epoch 3, Loss: 63.1694221496582\n",
      "Epoch 3, Loss: 77.94549560546875\n",
      "Epoch 3, Loss: 4705.9091796875\n",
      "Epoch 4, Loss: 363.27783203125\n",
      "Epoch 4, Loss: 370.3774719238281\n",
      "Epoch 4, Loss: 389.1224365234375\n",
      "Epoch 4, Loss: 79.32406616210938\n",
      "Epoch 4, Loss: 64.25384521484375\n",
      "Epoch 4, Loss: 68.03766632080078\n",
      "Epoch 4, Loss: 364.9261474609375\n",
      "Epoch 4, Loss: 377.2704772949219\n",
      "Epoch 4, Loss: 92.55659484863281\n",
      "Epoch 4, Loss: 69.87364959716797\n",
      "Epoch 4, Loss: 69.8010482788086\n",
      "Epoch 4, Loss: 68.43358612060547\n",
      "Epoch 4, Loss: 100.51498413085938\n",
      "Epoch 4, Loss: 396.3128967285156\n",
      "Epoch 4, Loss: 91.76434326171875\n",
      "Epoch 4, Loss: 86.04717254638672\n",
      "Epoch 4, Loss: 404.400634765625\n",
      "Epoch 4, Loss: 76.81773376464844\n",
      "Epoch 4, Loss: 58.200897216796875\n",
      "Epoch 4, Loss: 399.9609069824219\n",
      "Epoch 4, Loss: 366.8079833984375\n",
      "Epoch 4, Loss: 71.91390228271484\n",
      "Epoch 4, Loss: 420.0482177734375\n",
      "Epoch 4, Loss: 72.40253448486328\n",
      "Epoch 4, Loss: 73.06414794921875\n",
      "Epoch 4, Loss: 69.69730377197266\n",
      "Epoch 4, Loss: 65.26303100585938\n",
      "Epoch 4, Loss: 76.8045425415039\n",
      "Epoch 4, Loss: 73.10908508300781\n",
      "Epoch 4, Loss: 78.82881927490234\n",
      "Epoch 4, Loss: 75.45521545410156\n",
      "Epoch 4, Loss: 72.75125885009766\n",
      "Epoch 4, Loss: 102.65340423583984\n",
      "Epoch 4, Loss: 69.44334411621094\n",
      "Epoch 4, Loss: 78.18218994140625\n",
      "Epoch 4, Loss: 680.7341918945312\n",
      "Epoch 4, Loss: 359.0085754394531\n",
      "Epoch 4, Loss: 156.2482452392578\n",
      "Epoch 4, Loss: 79.299560546875\n",
      "Epoch 4, Loss: 75.49644470214844\n",
      "Epoch 4, Loss: 68.72270202636719\n",
      "Epoch 4, Loss: 516.250244140625\n",
      "Epoch 4, Loss: 63.360530853271484\n",
      "Epoch 4, Loss: 489.8657531738281\n",
      "Epoch 4, Loss: 430.3032531738281\n",
      "Epoch 4, Loss: 84.394287109375\n",
      "Epoch 4, Loss: 76.12713623046875\n",
      "Epoch 4, Loss: 95.75003814697266\n",
      "Epoch 4, Loss: 80.37872314453125\n",
      "Epoch 4, Loss: 86.58453369140625\n",
      "Epoch 4, Loss: 73.50863647460938\n",
      "Epoch 4, Loss: 362.65203857421875\n",
      "Epoch 4, Loss: 80.30472564697266\n",
      "Epoch 4, Loss: 97.8358383178711\n",
      "Epoch 4, Loss: 69.46907043457031\n",
      "Epoch 4, Loss: 380.706298828125\n",
      "Epoch 4, Loss: 72.33179473876953\n",
      "Epoch 4, Loss: 67.48652648925781\n",
      "Epoch 4, Loss: 82.25603485107422\n",
      "Epoch 4, Loss: 371.02008056640625\n",
      "Epoch 4, Loss: 110.23544311523438\n",
      "Epoch 4, Loss: 407.9280090332031\n",
      "Epoch 4, Loss: 69.1705093383789\n",
      "Epoch 4, Loss: 91.77852630615234\n",
      "Epoch 4, Loss: 81.43547821044922\n",
      "Epoch 4, Loss: 65.81603240966797\n",
      "Epoch 4, Loss: 76.61672973632812\n",
      "Epoch 4, Loss: 70.10101318359375\n",
      "Epoch 4, Loss: 102.16384887695312\n",
      "Epoch 4, Loss: 365.7352600097656\n",
      "Epoch 4, Loss: 61.43302917480469\n",
      "Epoch 4, Loss: 76.3271713256836\n",
      "Epoch 4, Loss: 83.57440185546875\n",
      "Epoch 4, Loss: 79.5905990600586\n",
      "Epoch 4, Loss: 68.14595794677734\n",
      "Epoch 4, Loss: 67.90436553955078\n",
      "Epoch 4, Loss: 167.70303344726562\n",
      "Epoch 4, Loss: 368.50811767578125\n",
      "Epoch 4, Loss: 66.60203552246094\n",
      "Epoch 4, Loss: 365.06622314453125\n",
      "Epoch 4, Loss: 78.32027435302734\n",
      "Epoch 4, Loss: 80.86643981933594\n",
      "Epoch 4, Loss: 61.40863037109375\n",
      "Epoch 4, Loss: 56.2454833984375\n",
      "Epoch 4, Loss: 634.802490234375\n",
      "Epoch 4, Loss: 88.19084167480469\n",
      "Epoch 4, Loss: 81.62600708007812\n",
      "Epoch 4, Loss: 82.29850006103516\n",
      "Epoch 4, Loss: 76.5893783569336\n",
      "Epoch 4, Loss: 155.69842529296875\n",
      "Epoch 4, Loss: 65.5848617553711\n",
      "Epoch 4, Loss: 66.41718292236328\n",
      "Epoch 4, Loss: 383.6450500488281\n",
      "Epoch 4, Loss: 73.17162322998047\n",
      "Epoch 4, Loss: 90.45545959472656\n",
      "Epoch 4, Loss: 74.07780456542969\n",
      "Epoch 4, Loss: 709.1464233398438\n",
      "Epoch 4, Loss: 364.68927001953125\n",
      "Epoch 4, Loss: 84.98115539550781\n",
      "Epoch 4, Loss: 110.92528533935547\n",
      "Epoch 4, Loss: 417.7787170410156\n",
      "Epoch 4, Loss: 197.56491088867188\n",
      "Epoch 4, Loss: 86.7463150024414\n",
      "Epoch 4, Loss: 72.25150299072266\n",
      "Epoch 4, Loss: 82.973388671875\n",
      "Epoch 4, Loss: 82.76579284667969\n",
      "Epoch 4, Loss: 384.20001220703125\n",
      "Epoch 4, Loss: 357.60235595703125\n",
      "Epoch 4, Loss: 68.13771057128906\n",
      "Epoch 4, Loss: 486.2425842285156\n",
      "Epoch 4, Loss: 368.62457275390625\n",
      "Epoch 4, Loss: 91.63127899169922\n",
      "Epoch 4, Loss: 68.12499237060547\n",
      "Epoch 4, Loss: 351.60198974609375\n",
      "Epoch 4, Loss: 190.02720642089844\n",
      "Epoch 4, Loss: 95.82571411132812\n",
      "Epoch 4, Loss: 4713.56640625\n",
      "Epoch 5, Loss: 362.1905822753906\n",
      "Epoch 5, Loss: 397.8246154785156\n",
      "Epoch 5, Loss: 151.83738708496094\n",
      "Epoch 5, Loss: 82.30271911621094\n",
      "Epoch 5, Loss: 106.70108032226562\n",
      "Epoch 5, Loss: 90.80545043945312\n",
      "Epoch 5, Loss: 358.5610656738281\n",
      "Epoch 5, Loss: 67.07588195800781\n",
      "Epoch 5, Loss: 57.53068923950195\n",
      "Epoch 5, Loss: 362.0226745605469\n",
      "Epoch 5, Loss: 74.82592010498047\n",
      "Epoch 5, Loss: 86.23168182373047\n",
      "Epoch 5, Loss: 71.45684814453125\n",
      "Epoch 5, Loss: 72.65740966796875\n",
      "Epoch 5, Loss: 75.71188354492188\n",
      "Epoch 5, Loss: 72.90923309326172\n",
      "Epoch 5, Loss: 77.60555267333984\n",
      "Epoch 5, Loss: 390.1393127441406\n",
      "Epoch 5, Loss: 91.40304565429688\n",
      "Epoch 5, Loss: 363.2275695800781\n",
      "Epoch 5, Loss: 79.78909301757812\n",
      "Epoch 5, Loss: 67.42588806152344\n",
      "Epoch 5, Loss: 62.215667724609375\n",
      "Epoch 5, Loss: 66.85895538330078\n",
      "Epoch 5, Loss: 86.31034851074219\n",
      "Epoch 5, Loss: 447.0606384277344\n",
      "Epoch 5, Loss: 64.22946166992188\n",
      "Epoch 5, Loss: 384.84698486328125\n",
      "Epoch 5, Loss: 188.5283966064453\n",
      "Epoch 5, Loss: 68.06444549560547\n",
      "Epoch 5, Loss: 356.5102233886719\n",
      "Epoch 5, Loss: 387.0567321777344\n",
      "Epoch 5, Loss: 73.56227111816406\n",
      "Epoch 5, Loss: 381.2821350097656\n",
      "Epoch 5, Loss: 77.93406677246094\n",
      "Epoch 5, Loss: 65.89176940917969\n",
      "Epoch 5, Loss: 74.68899536132812\n",
      "Epoch 5, Loss: 75.26934814453125\n",
      "Epoch 5, Loss: 65.6583023071289\n",
      "Epoch 5, Loss: 110.16968536376953\n",
      "Epoch 5, Loss: 73.90593719482422\n",
      "Epoch 5, Loss: 387.888671875\n",
      "Epoch 5, Loss: 65.864501953125\n",
      "Epoch 5, Loss: 340.4685363769531\n",
      "Epoch 5, Loss: 396.6865234375\n",
      "Epoch 5, Loss: 70.38082885742188\n",
      "Epoch 5, Loss: 76.20952606201172\n",
      "Epoch 5, Loss: 121.84986877441406\n",
      "Epoch 5, Loss: 106.9322509765625\n",
      "Epoch 5, Loss: 89.03947448730469\n",
      "Epoch 5, Loss: 123.19635772705078\n",
      "Epoch 5, Loss: 336.0933837890625\n",
      "Epoch 5, Loss: 79.06756591796875\n",
      "Epoch 5, Loss: 92.81380462646484\n",
      "Epoch 5, Loss: 77.1766357421875\n",
      "Epoch 5, Loss: 69.2286148071289\n",
      "Epoch 5, Loss: 69.388427734375\n",
      "Epoch 5, Loss: 98.0148696899414\n",
      "Epoch 5, Loss: 73.32760620117188\n",
      "Epoch 5, Loss: 196.35025024414062\n",
      "Epoch 5, Loss: 87.50946807861328\n",
      "Epoch 5, Loss: 435.3686828613281\n",
      "Epoch 5, Loss: 102.97064208984375\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "linear_mapper.train()\n",
    "linear_optimizer = torch.optim.Adam(linear_mapper.parameters(), lr=1e-5, weight_decay=0)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "def calculate_ctc_loss(log_probs, target_sequence):\n",
    "    \"\"\"Calculates CTC loss.\"\"\"\n",
    "    # Create input_lengths and target_lengths tensors\n",
    "    input_lengths = torch.tensor([batch_size])  # Batch size of 1\n",
    "    target_lengths = torch.tensor([batch_size])  # Batch size of 1\n",
    "\n",
    "    # Calculate CTC loss\n",
    "    loss = F.ctc_loss(\n",
    "        log_probs,\n",
    "        target_sequence,\n",
    "        input_lengths=input_lengths,\n",
    "        target_lengths=target_lengths\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "\n",
    "def prepare_folders():\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    if not os.path.exists(OUTPUTS_DIR):\n",
    "        os.makedirs(OUTPUTS_DIR)\n",
    "    \n",
    "\n",
    "def load_last_checkpoint(model_dir):\n",
    "    increment = -1\n",
    "    name_format = r\"linear_mapper_.*(\\d+)\\.pth$\"\n",
    "    # Load the latest version\n",
    "    pth_files = [f for f in os.listdir(model_dir) if re.search(name_format, f)]\n",
    "    increment = len(pth_files)\n",
    "\n",
    "    if not pth_files:\n",
    "        warnings.warn(\"No .pth files found in the model directory! Starting from scratch!\")\n",
    "    else:\n",
    "        # Sort the files by their index (last number)\n",
    "        pth_files.sort(key=lambda x: int(re.search(name_format, x)[1]))\n",
    "\n",
    "        # Load the latest version\n",
    "        checkpoint = pth_files[-1]  # Load the last element (highest index)\n",
    "        match = re.search(name_format, checkpoint)\n",
    "        if match:\n",
    "            increment = int(match[1])\n",
    "            # Load the linear layer's parameters\n",
    "            linear_mapper.load_state_dict(\n",
    "                torch.load(f\"{model_dir}/{checkpoint}\")\n",
    "            )\n",
    "        else:\n",
    "            warnings.warn(\"Couldn't find a model! Starting from scratch!\")\n",
    "    return increment\n",
    "\n",
    "prepare_folders()\n",
    "increment = load_last_checkpoint(MODEL_DIR)\n",
    "\n",
    "\n",
    "def write_to_csv(row):\n",
    "    with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for i in range(0, len(features_dataset), batch_size):\n",
    "        batch_data = features_dataset.shuffle()[i:i + batch_size]\n",
    "\n",
    "\n",
    "        input_lengths = torch.zeros(batch_size, dtype=torch.uint32)\n",
    "        max_len = max(map(len, batch_data[\"features\"]))\n",
    "\n",
    "        input_batch = torch.zeros((batch_size, max_len, wavlm_model.config.hidden_size))\n",
    "        for i, feat in enumerate(batch_data[\"features\"]):\n",
    "            input_batch[i, :len(feat)] = torch.tensor(feat)\n",
    "            input_lengths[i] = len(feat)\n",
    "\n",
    "        log_probs = linear_mapper(\n",
    "            input_batch.reshape(\n",
    "                (batch_size, -1, wavlm_model.config.hidden_size)\n",
    "            )\n",
    "        )\n",
    "        targets = [phoneme_recognizer.tokenize(string) for string in batch_data[\"target_phonemes\"]]\n",
    "        target_lengths = torch.zeros(batch_size, dtype=torch.uint8)\n",
    "        max_len = max(map(lambda x: x.shape[0], targets))\n",
    "\n",
    "        target_batch = torch.zeros((batch_size, max_len))\n",
    "        for i, target in enumerate(targets):\n",
    "            target_batch[i, :target.shape[0]] = target\n",
    "            target_lengths[i] = target.shape[0]\n",
    "\n",
    "        loss = F.ctc_loss(\n",
    "            log_probs.transpose(0, 1),\n",
    "            target_batch,\n",
    "            input_lengths=torch.tensor([x.shape[0] for x in log_probs]),\n",
    "            target_lengths=target_lengths\n",
    "        )\n",
    "        linear_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        linear_optimizer.step()\n",
    "        for logs, target_phons in zip(phoneme_recognizer.classify_to_phonemes(log_probs), batch_data[\"target_phonemes\"]):\n",
    "            write_to_csv(\n",
    "                [\n",
    "                    increment, epoch, i, loss.item(), \"\".join(logs), \"\".join(target_phons)\n",
    "                ]\n",
    "            )\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        increment += 1\n",
    "    torch.save(\n",
    "        linear_mapper.state_dict(),\n",
    "        f\"{MODEL_DIR}/linear_mapper_epoch_{epoch}_step_{i}_{increment}.pth\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e2537",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcce0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "\n",
    "with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        losses.append(float(row[3]))\n",
    "\n",
    "plt.plot(losses, label=\"Loss over training step\", linestyle='dotted')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df87423",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we want a phoneme recognition.\n",
    "It means to train the last layer of the model to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b488c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.4194483757019043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/dev/asr/Lemanic-Life-Sciences-Hackathon-2025/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.888230800628662\n",
      "Epoch 0, Loss: 1.146170735359192\n",
      "Epoch 0, Loss: 6.249912738800049\n",
      "Epoch 0, Loss: 1.2091354131698608\n",
      "Epoch 0, Loss: 3.8059654235839844\n",
      "Epoch 0, Loss: 2.063833713531494\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "phoneme_recognizer.train()\n",
    "linear_optimizer = torch.optim.Adam(\n",
    "    phoneme_recognizer.phoneme_classifier.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=0\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_ctc_loss(log_probs, target_sequence):\n",
    "    \"\"\"Calculates CTC loss.\"\"\"\n",
    "    # Create input_lengths and target_lengths tensors\n",
    "    input_lengths = torch.tensor([1])  # Batch size of 1\n",
    "    target_lengths = torch.tensor([1])  # Batch size of 1\n",
    "\n",
    "    # Calculate CTC loss\n",
    "    loss = F.ctc_loss(\n",
    "        log_probs,\n",
    "        target_sequence,\n",
    "        input_lengths=input_lengths,\n",
    "        target_lengths=target_lengths\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "\n",
    "\n",
    "def prepare_folders():\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    if not os.path.exists(OUTPUTS_DIR):\n",
    "        os.makedirs(OUTPUTS_DIR)\n",
    "    \n",
    "\n",
    "def load_last_checkpoint(model_dir):\n",
    "    increment = -1\n",
    "    # Load the latest version\n",
    "    pth_files = [f for f in os.listdir(model_dir) if f.endswith(\".pth\")]\n",
    "    increment = len(pth_files)\n",
    "\n",
    "    if not pth_files:\n",
    "        warnings.warn(\"No .pth files found in the model directory! Starting from scratch!\")\n",
    "    else:\n",
    "        # Sort the files by their index (last number)\n",
    "        pth_files.sort(key=lambda x: int(re.search(r\"(\\d+)\\.pth$\", x)[1]))\n",
    "\n",
    "        # Load the latest version\n",
    "        checkpoint = pth_files[-1]  # Load the last element (highest index)\n",
    "        match = re.search(r\"(\\d+)\\.pth$\", checkpoint)\n",
    "        if match:\n",
    "            increment = int(match[1])\n",
    "            # Load the linear layer's parameters\n",
    "            phoneme_recognizer.phoneme_classifier.load_state_dict(\n",
    "                torch.load(f\"{model_dir}/{checkpoint}\")\n",
    "            )\n",
    "        else:\n",
    "            warnings.warn(\"Couldn't find a model! Starting from scratch!\")\n",
    "    return increment\n",
    "\n",
    "prepare_folders()\n",
    "increment = load_last_checkpoint(MODEL_DIR)\n",
    "\n",
    "# Freeze the wavlm model\n",
    "for param in phoneme_recognizer.wavlm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "def write_to_csv(row):\n",
    "    with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(dataset.shuffle().select(range(50))):\n",
    "        inputs = get_audio_features(data)\n",
    "        log_probs = phoneme_recognizer(inputs)\n",
    "        split_phonemes = smart_split_coder(data[\"phoneme_sequence\"][0])\n",
    "        target = phoneme_recognizer.tokenize(split_phonemes)\n",
    "        loss = calculate_ctc_loss(log_probs[0], target.reshape([1, -1]))\n",
    "        linear_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        linear_optimizer.step()\n",
    "        write_to_csv(\n",
    "            [\n",
    "                increment, epoch, i, loss.item(),\n",
    "                \"\".join(phoneme_recognizer.classify_to_phonemes(log_probs)[0]),\n",
    "                \"\".join(split_phonemes)\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        increment += 1\n",
    "        torch.save(\n",
    "            phoneme_recognizer.phoneme_classifier.state_dict(),\n",
    "            f\"{MODEL_DIR}/phoneme_classifier_epoch_{epoch}_step_{i}_{increment}.pth\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d7f10",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "\n",
    "We have a model roughly trained for phonemes.\n",
    "We want a binary classification though.\n",
    "We won't do that for now as it would be an end-to-end pipeline, defeating the purpose of the created pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
