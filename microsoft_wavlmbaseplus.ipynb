{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b6c7c4",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Let's create a model first, with some vocab.\n",
    "The output is a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f115131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in ./.venv/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.5.1)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in ./.venv/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in ./.venv/lib/python3.12/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.venv/lib/python3.12/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in ./.venv/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in ./.venv/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in ./.venv/lib/python3.12/site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.venv/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in ./.venv/lib/python3.12/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.12/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (80.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install librosa numpy soundfile torch torchaudio datasets transformers matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d917c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/2 [00:00<?, ? examples/s]/home/hugo/Documents/dev/asr/Lemanic-Life-Sciences-Hackathon-2025/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2/2 [00:00<00:00,  3.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities shape: (2, 292, 50)\n",
      "Recognized phoneme sequence: bɐʎsɔʎɔœɔœỹyrːuʎɲʌɡfuʎtʃruɛɐkust[UNK]rkʊʌuʁɔɡœɾ<blank>bʎɔʎwɔŋ[UNK]ʃ[UNK]ʎɛiœɐiui[UNK]lb<blank>mirur)ʃjiɡnkt[UNK]rurɐ<blank>œrœi̪it̪j(iuɾauiʎbjyœøbœtvjɛuɔtrɛ<blank>œ[UNK]œzwtŋɾ[UNK]rʎlɛɒɔŋtut)uɡtʎnbɲjnsʃɾtɐyi)iumɐ(iɐ[UNK]ʎpɲiʌføsfyirːr[PAD]jy\n",
      "Transcript for reference: MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import WavLMModel, AutoFeatureExtractor\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "# PhonemeRecognizer: WavLM + CTC for phoneme speech recognition\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "# Load vocab from file\n",
    "with open(\"phoneme_tokenizer/vocab.json\") as vocab_file:\n",
    "    vocab = json.load(vocab_file)\n",
    "\n",
    "# IT + FR phonemes + blank\n",
    "VOCAB = {\n",
    "  \"0\": \"ʒ\",\n",
    "  \"1\": \"ɹ\",\n",
    "  \"2\": \"j\",\n",
    "  \"3\": \"d\",\n",
    "  \"4\": \"ɲ\",\n",
    "  \"5\": \"ʌ\",\n",
    "  \"6\": \"[UNK]\",\n",
    "  \"7\": \"ɒ\",\n",
    "  \"8\": \"ɐ\",\n",
    "  \"9\": \"ʃ\",\n",
    "  \"10\": \"ɔ\",\n",
    "  \"11\": \"f\",\n",
    "  \"12\": \"ø\",\n",
    "  \"13\": \"z\",\n",
    "  \"14\": \"ŋ\",\n",
    "  \"15\": \"i\",\n",
    "  \"16\": \"u\",\n",
    "  \"17\": \"̃\",\n",
    "  \"18\": \"o\",\n",
    "  \"19\": \"œ\",\n",
    "  \"20\": \"a\",\n",
    "  \"21\": \"(\",\n",
    "  \"22\": \"ə\",\n",
    "  \"23\": \"ɜ\",\n",
    "  \"24\": \"ɾ\",\n",
    "  \"25\": \"ː\",\n",
    "  \"26\": \"̪\",\n",
    "  \"27\": \"e\",\n",
    "  \"28\": \"b\",\n",
    "  \"29\": \"ʁ\",\n",
    "  \"30\": \"w\",\n",
    "  \"31\": \"n\",\n",
    "  \"32\": \"p\",\n",
    "  \"33\": \"y\",\n",
    "  \"34\": \"ɡ\",\n",
    "  \"35\": \"ɪ\",\n",
    "  \"36\": \"r\",\n",
    "  \"37\": \"v\",\n",
    "  \"38\": \"t\",\n",
    "  \"39\": \")\",\n",
    "  \"40\": \"m\",\n",
    "  \"41\": \"k\",\n",
    "  \"42\": \"ʊ\",\n",
    "  \"43\": \"ʎ\",\n",
    "  \"44\": \"ɑ\",\n",
    "  \"45\": \"s\",\n",
    "  \"46\": \"l\",\n",
    "  \"47\": \"[PAD]\",\n",
    "  \"48\": \"ɛ\",\n",
    "  \"49\": '<blank>' # blank token for CTC\n",
    "}\n",
    "PHONEME_DICT = {v: int(k) for k, v in VOCAB.items()}\n",
    "\n",
    "NUM_PHONEMES = len(PHONEME_DICT)\n",
    "\n",
    "class PhonemeRecognizer(nn.Module):\n",
    "    def __init__(self, wavlm_model, num_phonemes=NUM_PHONEMES):\n",
    "        super().__init__()\n",
    "        self.wavlm = wavlm_model\n",
    "\n",
    "        # Get the hidden size from the WavLM model\n",
    "        hidden_size = self.wavlm.config.hidden_size\n",
    "\n",
    "        # Add a dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Linear layer to map from WavLM hidden states to phoneme classes (including blank)\n",
    "        self.phoneme_classifier = nn.Linear(hidden_size, num_phonemes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Get WavLM embeddings\n",
    "        outputs = self.wavlm(**inputs)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        # Apply dropout\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "\n",
    "        # Apply the linear layer to get logits for each time step\n",
    "        logits = self.phoneme_classifier(hidden_states)\n",
    "\n",
    "        # Apply log softmax for CTC loss\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        return log_probs\n",
    "    \n",
    "    def classify_to_phonemes(self, log_probs):\n",
    "        # Simple greedy decoding (for demonstration)\n",
    "        # In a real system, you would use beam search with ctcdecode\n",
    "        predictions = torch.argmax(log_probs, dim=-1).cpu().numpy()\n",
    "\n",
    "        # Convert to phoneme sequences with CTC decoding rules (merge repeats, remove blanks)\n",
    "        phoneme_sequences = []\n",
    "        for pred_seq in predictions:\n",
    "            seq = []\n",
    "            prev = -1\n",
    "            for p in pred_seq:\n",
    "                # Skip blanks (index 0) and repeated phonemes (CTC rules)\n",
    "                if p != 0 and p != prev:\n",
    "                    # Convert index back to phoneme\n",
    "                    phoneme = list(PHONEME_DICT.keys())[list(PHONEME_DICT.values()).index(p)]\n",
    "                    seq.append(phoneme)\n",
    "                prev = p\n",
    "            phoneme_sequences.append(seq)\n",
    "\n",
    "        return phoneme_sequences\n",
    "\n",
    "\n",
    "    def recognize(self, inputs, beam_width=100):\n",
    "        \"\"\"Perform phoneme recognition without beam search decoding\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Forward pass to get log probabilities\n",
    "            log_probs = self(inputs)\n",
    "\n",
    "            return self.classify_to_phonemes(log_probs)\n",
    "\n",
    "    def tokenize(self, char_list):\n",
    "        \"\"\"Go from a list of characters to a list of indices.\"\"\"\n",
    "        return torch.tensor([PHONEME_DICT[x] for x in char_list])\n",
    "    \n",
    "    def get_embedding(self, char_list):\n",
    "        tokens = self.tokenize(char_list)\n",
    "        out_tensor = torch.zeros((len(tokens), len(PHONEME_DICT)))\n",
    "        for i, token_id in enumerate(tokens):\n",
    "            out_tensor[i, token_id] = 1\n",
    "        return out_tensor\n",
    "\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "# Method A: Using the PhonemeRecognizer for speech-to-phoneme ASR\n",
    "# ————————————————————————————————————————————————————————————————————————\n",
    "\n",
    "# 1. Load the feature extractor and model\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/wavlm-base-plus\")\n",
    "wavlm_model = WavLMModel.from_pretrained(\"microsoft/wavlm-base-plus\")\n",
    "\n",
    "# Create the phoneme recognizer with the WavLM model\n",
    "phoneme_recognizer = PhonemeRecognizer(wavlm_model)\n",
    "phoneme_recognizer.eval()  # disable dropout, etc.\n",
    "\n",
    "# 2. Load an example audio file (here using a small demo from `datasets`)\n",
    "#    The `audio[\"array\"]` is a NumPy array of floats; sampling_rate is an int.\n",
    "ds = datasets.load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "audio_sample = ds[0][\"audio\"][\"array\"]\n",
    "sr = ds[0][\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "def get_audio_features(batch):\n",
    "    # 3. Preprocess (pad/truncate + batch‐dim)\n",
    "    for data_row in batch:\n",
    "        if data_row[\"sampling_rate\"] != 16000:\n",
    "            raise NotImplementedError(\n",
    "                f\"No sampling rate can be different from 16000, is {data_row[\"sampling_rate\"]}\"\n",
    "            )\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        [data_row[\"array\"] for data_row in batch],\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\",        # => PyTorch tensors\n",
    "        padding=True,               # pad to longest in batch\n",
    "    )\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def run_inference(batch, model):\n",
    "    \"\"\"Return log probs and most likely phonemes.\"\"\"\n",
    "    inputs = get_audio_features(batch[\"audio\"])\n",
    "\n",
    "    # 4. Inference for phoneme recognition\n",
    "    with torch.no_grad():\n",
    "        # Get phoneme log probabilities\n",
    "        log_probs = model(inputs)\n",
    "\n",
    "        # Recognize phoneme sequence\n",
    "        phoneme_sequences = model.recognize(inputs)\n",
    "\n",
    "    return {\"log_probs\": log_probs, \"phonemes\": phoneme_sequences}\n",
    "\n",
    "predicted = ds.select(range(2)).map(\n",
    "    lambda data_row: run_inference(data_row, phoneme_recognizer),\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(\"Log probabilities shape:\", np.shape(predicted[\"log_probs\"]))  # (batch_size, seq_len, num_phonemes)\n",
    "print(\"Recognized phoneme sequence:\", \"\".join(predicted[\"phonemes\"][0]))\n",
    "print(\"Transcript for reference:\", ds[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5207f7",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's load our data in a Hugging Face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65d3d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'target_phonemes'],\n",
      "    num_rows: 932\n",
      "})\n",
      "{'path': 'Hackathon_ASR/2_Audiofiles/Decoding_IT_T1/1001_edugame2023_59aa8ecf74c44db2adf56d71d1705cf5_1de23ac3deaf4b4d8c7db6d0cc9d6bfe.wav', 'array': array([0.        , 0.        , 0.        , ..., 0.00378418, 0.00424194,\n",
      "       0.        ], shape=(364544,)), 'sampling_rate': 16000}\n",
      "['v', 'u', 'z', 'o', '[PAD]', 's', 'e', 'ɡ', 'a', '[PAD]', 'k', 'l', 'o', 'f', 'ɛ', 'n', 'o', '[PAD]', 'r', 'a', 'v', 'i', 'ʎ', 'o', '[PAD]', 'd', 'a', '[PAD]', 'p', 'e', '[PAD]', 't', 'a', 'r', 's', 'e', '[PAD]', 'd', 'o', 'r', 'i', 'd', 'z', 'ː', 'a', '[PAD]', 'p', 'r', 'a', 't', 'e', 'ʎ', 'a', '[PAD]', 'a', 'ː', '[PAD]', 'ɛ', 'r', 'ɾ', 'e', '[PAD]', 'l', 'o', '[PAD]', 'b', 'e', 'ɲ', 'o', 'l', 'e', '[PAD]', 'f', 'l', 'a', '[PAD]', 'v', 'ɛ', 's', 't', 'r', 'o', '[PAD]', 'k', 'ʊ', 'ɲ', 'a', 'r', 'i', 'p', 'ː', 'o']\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# 1. Location of your CSV\n",
    "# csv_file = \"train_phonemes_clean.csv\"  # replace with your path\n",
    "csv_file = \"ground_truth_it_coder_2.csv\"  # replace with your path\n",
    "\n",
    "# 2. Define initial features: audio paths as plain strings, phonemes as plain strings\n",
    "features = datasets.Features({\n",
    "    \"file_name\": datasets.Value(\"string\"),\n",
    "    \"phoneme_sequence\": datasets.Value(\"string\"),\n",
    "})\n",
    "\n",
    "# 3. Load the CSV into a DatasetDict (default split is 'train')\n",
    "dataset = datasets.load_dataset(\"csv\", data_files=csv_file, features=features, split=\"train\")\n",
    "\n",
    "# 4. Rename the audio-path column to 'audio' (required by Audio feature)\n",
    "dataset = dataset.rename_column(\"file_name\", \"audio\")\n",
    "\n",
    "# 5. Cast 'audio' to the Audio type (will load the file when you access it)\n",
    "dataset = dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16_000))\n",
    "\n",
    "# 6. Map + split phoneme strings into lists\n",
    "def split_phonemes(data_row):\n",
    "    \"\"\"Split each phoneme into a list.\"\"\"\n",
    "    output = []\n",
    "    in_brackets = False\n",
    "    for char in data_row[\"phoneme_sequence\"]:\n",
    "        if in_brackets:\n",
    "            output[-1] += char\n",
    "        else:\n",
    "            output.append(char)\n",
    "\n",
    "        if char == '[':\n",
    "            in_brackets = True\n",
    "        elif char == ']':\n",
    "            in_brackets = False\n",
    "    data_row[\"target_phonemes\"] = output\n",
    "    return data_row\n",
    "\n",
    "\n",
    "dataset = dataset.map(split_phonemes, remove_columns=[\"phoneme_sequence\"])\n",
    "\n",
    "# 7. Cast the phoneme_sequence column to a Sequence of strings\n",
    "dataset = dataset.cast_column(\n",
    "    \"target_phonemes\",\n",
    "    datasets.Sequence(feature=datasets.Value(\"string\"))\n",
    ")\n",
    "\n",
    "# Now 'dataset' has:\n",
    "#   - dataset[i][\"audio\"] → { \"array\": np.ndarray, \"sampling_rate\": 16000 }\n",
    "#   - dataset[i][\"target_phonemes\"] → list of strings\n",
    "print(dataset)\n",
    "print(dataset[0][\"audio\"])\n",
    "print(dataset[0][\"target_phonemes\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf53be",
   "metadata": {},
   "source": [
    "## Putting stuff together\n",
    "\n",
    "Now we run the model on our in-house dataset.\n",
    "We will extract the features so that it is easier to work with latter on.\n",
    "For this version we don't train the model, only a fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb0ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16/16 [00:21<00:00,  1.36s/ examples]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['target_phonemes', 'features'],\n",
       "    num_rows: 16\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavlm_model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    features_dataset = dataset.select(range(16)).map(\n",
    "        lambda batch: {\n",
    "            \"features\": wavlm_model(**get_audio_features(batch[\"audio\"])).last_hidden_state\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=[\"audio\"],\n",
    "        batch_size=15\n",
    "    )\n",
    "\n",
    "features_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690dea4",
   "metadata": {},
   "source": [
    "## Defining a new linear layer\n",
    "\n",
    "As a speed-up, we simply create a linear layer to map from the extracted features to the phonemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dfda0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PhonemeMapper(nn.Module):\n",
    "    def __init__(self, features_size, num_phonemes=NUM_PHONEMES):\n",
    "        super().__init__()\n",
    "\n",
    "        # Add a dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Linear layer to map from WavLM hidden states to phoneme classes (including blank)\n",
    "        self.phoneme_classifier = nn.Linear(features_size, num_phonemes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Apply dropout\n",
    "        hidden_states = self.dropout(inputs)\n",
    "\n",
    "        # Apply the linear layer to get logits for each time step\n",
    "        logits = self.phoneme_classifier(hidden_states)\n",
    "\n",
    "        # Apply log softmax for CTC loss\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        return log_probs\n",
    "    \n",
    "    def classify_to_phonemes(self, log_probs):\n",
    "        # Simple greedy decoding (for demonstration)\n",
    "        # In a real system, you would use beam search with ctcdecode\n",
    "        predictions = torch.argmax(log_probs, dim=-1).cpu().numpy()\n",
    "\n",
    "        # Convert to phoneme sequences with CTC decoding rules (merge repeats, remove blanks)\n",
    "        phoneme_sequences = []\n",
    "        for pred_seq in predictions:\n",
    "            seq = []\n",
    "            prev = -1\n",
    "            for p in pred_seq:\n",
    "                # Skip blanks (index 0) and repeated phonemes (CTC rules)\n",
    "                if p != 0 and p != prev:\n",
    "                    # Convert index back to phoneme\n",
    "                    phoneme = list(PHONEME_DICT.keys())[list(PHONEME_DICT.values()).index(p)]\n",
    "                    seq.append(phoneme)\n",
    "                prev = p\n",
    "            phoneme_sequences.append(seq)\n",
    "\n",
    "        return phoneme_sequences\n",
    "    \n",
    "linear_mapper = PhonemeMapper(wavlm_model.config.hidden_size, NUM_PHONEMES)\n",
    "\n",
    "wavlm_model.config.hidden_size, NUM_PHONEMES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dc4765",
   "metadata": {},
   "source": [
    "## Model fine-tuning\n",
    "\n",
    "Now that the linear layer is ready, we can simply train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c79bfb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 61.96426010131836\n",
      "Epoch 0, Loss: 60.95927429199219\n",
      "Epoch 1, Loss: 62.19858932495117\n",
      "Epoch 1, Loss: 61.010189056396484\n",
      "Epoch 2, Loss: 63.47453308105469\n",
      "Epoch 2, Loss: 59.55779266357422\n",
      "Epoch 3, Loss: 63.83512878417969\n",
      "Epoch 3, Loss: 62.583133697509766\n",
      "Epoch 4, Loss: 63.73712921142578\n",
      "Epoch 4, Loss: 62.101200103759766\n",
      "Epoch 5, Loss: 62.10984420776367\n",
      "Epoch 5, Loss: 65.0787582397461\n",
      "Epoch 6, Loss: 61.56394958496094\n",
      "Epoch 6, Loss: 63.68605422973633\n",
      "Epoch 7, Loss: 58.373050689697266\n",
      "Epoch 7, Loss: 57.65672302246094\n",
      "Epoch 8, Loss: 61.475162506103516\n",
      "Epoch 8, Loss: 67.39363861083984\n",
      "Epoch 9, Loss: 60.314186096191406\n",
      "Epoch 9, Loss: 62.20448684692383\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "linear_mapper.train()\n",
    "linear_optimizer = torch.optim.Adam(linear_mapper.parameters(), lr=1e-5, weight_decay=0)\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "def calculate_ctc_loss(log_probs, target_sequence):\n",
    "    \"\"\"Calculates CTC loss.\"\"\"\n",
    "    # Create input_lengths and target_lengths tensors\n",
    "    input_lengths = torch.tensor([batch_size])  # Batch size of 1\n",
    "    target_lengths = torch.tensor([batch_size])  # Batch size of 1\n",
    "\n",
    "    # Calculate CTC loss\n",
    "    loss = F.ctc_loss(\n",
    "        log_probs,\n",
    "        target_sequence,\n",
    "        input_lengths=input_lengths,\n",
    "        target_lengths=target_lengths\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "\n",
    "def prepare_folders():\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    if not os.path.exists(OUTPUTS_DIR):\n",
    "        os.makedirs(OUTPUTS_DIR)\n",
    "    \n",
    "\n",
    "def load_last_checkpoint(model_dir):\n",
    "    increment = -1\n",
    "    name_format = r\"linear_mapper_.*(\\d+)\\.pth$\"\n",
    "    # Load the latest version\n",
    "    pth_files = [f for f in os.listdir(model_dir) if re.search(name_format, f)]\n",
    "    increment = len(pth_files)\n",
    "\n",
    "    if not pth_files:\n",
    "        warnings.warn(\"No .pth files found in the model directory! Starting from scratch!\")\n",
    "    else:\n",
    "        # Sort the files by their index (last number)\n",
    "        pth_files.sort(key=lambda x: int(re.search(name_format, x)[1]))\n",
    "\n",
    "        # Load the latest version\n",
    "        checkpoint = pth_files[-1]  # Load the last element (highest index)\n",
    "        match = re.search(name_format, checkpoint)\n",
    "        if match:\n",
    "            increment = int(match[1])\n",
    "            # Load the linear layer's parameters\n",
    "            linear_mapper.load_state_dict(\n",
    "                torch.load(f\"{model_dir}/{checkpoint}\")\n",
    "            )\n",
    "        else:\n",
    "            warnings.warn(\"Couldn't find a model! Starting from scratch!\")\n",
    "    return increment\n",
    "\n",
    "prepare_folders()\n",
    "increment = load_last_checkpoint(MODEL_DIR)\n",
    "\n",
    "\n",
    "def write_to_csv(row):\n",
    "    with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for i in range(0, len(features_dataset), batch_size):\n",
    "        batch_data = features_dataset.shuffle()[i:i + batch_size]\n",
    "\n",
    "\n",
    "        input_lengths = torch.zeros(batch_size, dtype=torch.uint32)\n",
    "        max_len = max(map(len, batch_data[\"features\"]))\n",
    "\n",
    "        input_batch = torch.zeros((batch_size, max_len, wavlm_model.config.hidden_size))\n",
    "        for i, feat in enumerate(batch_data[\"features\"]):\n",
    "            input_batch[i, :len(feat)] = torch.tensor(feat)\n",
    "            input_lengths[i] = len(feat)\n",
    "\n",
    "        log_probs = linear_mapper(\n",
    "            input_batch.reshape(\n",
    "                (batch_size, -1, wavlm_model.config.hidden_size)\n",
    "            )\n",
    "        )\n",
    "        targets = [phoneme_recognizer.tokenize(string) for string in batch_data[\"target_phonemes\"]]\n",
    "        target_lengths = torch.zeros(batch_size, dtype=torch.uint8)\n",
    "        max_len = max(map(lambda x: x.shape[0], targets))\n",
    "\n",
    "        target_batch = torch.zeros((batch_size, max_len))\n",
    "        for i, target in enumerate(targets):\n",
    "            target_batch[i, :target.shape[0]] = target\n",
    "            target_lengths[i] = target.shape[0]\n",
    "\n",
    "        loss = F.ctc_loss(\n",
    "            log_probs.transpose(0, 1),\n",
    "            target_batch,\n",
    "            input_lengths=torch.tensor([x.shape[0] for x in log_probs]),\n",
    "            target_lengths=target_lengths\n",
    "        )\n",
    "        linear_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        linear_optimizer.step()\n",
    "        for i in range(batch_size):\n",
    "            write_to_csv(\n",
    "                [\n",
    "                    increment, epoch, i, loss.item(),\n",
    "                    \"\".join(phoneme_recognizer.classify_to_phonemes(log_probs)[i]),\n",
    "                    \"\".join(batch_data[\"target_phonemes\"][i])\n",
    "                ]\n",
    "            )\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        increment += 1\n",
    "    torch.save(\n",
    "        linear_mapper.state_dict(),\n",
    "        f\"{MODEL_DIR}/linear_mapper_epoch_{epoch}_step_{i}_{increment}.pth\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e2537",
   "metadata": {},
   "source": [
    "## View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcce0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "\n",
    "with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        losses.append(float(row[3]))\n",
    "\n",
    "plt.plot(losses, label=\"Loss over training step\", linestyle='dotted')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df87423",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now we want a phoneme recognition.\n",
    "It means to train the last layer of the model to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b488c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.4194483757019043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/Documents/dev/asr/Lemanic-Life-Sciences-Hackathon-2025/.venv/lib/python3.12/site-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.888230800628662\n",
      "Epoch 0, Loss: 1.146170735359192\n",
      "Epoch 0, Loss: 6.249912738800049\n",
      "Epoch 0, Loss: 1.2091354131698608\n",
      "Epoch 0, Loss: 3.8059654235839844\n",
      "Epoch 0, Loss: 2.063833713531494\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "phoneme_recognizer.train()\n",
    "linear_optimizer = torch.optim.Adam(\n",
    "    phoneme_recognizer.phoneme_classifier.parameters(),\n",
    "    lr=1e-3,\n",
    "    weight_decay=0\n",
    ")\n",
    "\n",
    "\n",
    "def calculate_ctc_loss(log_probs, target_sequence):\n",
    "    \"\"\"Calculates CTC loss.\"\"\"\n",
    "    # Create input_lengths and target_lengths tensors\n",
    "    input_lengths = torch.tensor([1])  # Batch size of 1\n",
    "    target_lengths = torch.tensor([1])  # Batch size of 1\n",
    "\n",
    "    # Calculate CTC loss\n",
    "    loss = F.ctc_loss(\n",
    "        log_probs,\n",
    "        target_sequence,\n",
    "        input_lengths=input_lengths,\n",
    "        target_lengths=target_lengths\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "MODEL_DIR = \"models\"\n",
    "OUTPUTS_DIR = \"outputs\"\n",
    "\n",
    "\n",
    "def prepare_folders():\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    if not os.path.exists(OUTPUTS_DIR):\n",
    "        os.makedirs(OUTPUTS_DIR)\n",
    "    \n",
    "\n",
    "def load_last_checkpoint(model_dir):\n",
    "    increment = -1\n",
    "    # Load the latest version\n",
    "    pth_files = [f for f in os.listdir(model_dir) if f.endswith(\".pth\")]\n",
    "    increment = len(pth_files)\n",
    "\n",
    "    if not pth_files:\n",
    "        warnings.warn(\"No .pth files found in the model directory! Starting from scratch!\")\n",
    "    else:\n",
    "        # Sort the files by their index (last number)\n",
    "        pth_files.sort(key=lambda x: int(re.search(r\"(\\d+)\\.pth$\", x)[1]))\n",
    "\n",
    "        # Load the latest version\n",
    "        checkpoint = pth_files[-1]  # Load the last element (highest index)\n",
    "        match = re.search(r\"(\\d+)\\.pth$\", checkpoint)\n",
    "        if match:\n",
    "            increment = int(match[1])\n",
    "            # Load the linear layer's parameters\n",
    "            phoneme_recognizer.phoneme_classifier.load_state_dict(\n",
    "                torch.load(f\"{model_dir}/{checkpoint}\")\n",
    "            )\n",
    "        else:\n",
    "            warnings.warn(\"Couldn't find a model! Starting from scratch!\")\n",
    "    return increment\n",
    "\n",
    "prepare_folders()\n",
    "increment = load_last_checkpoint(MODEL_DIR)\n",
    "\n",
    "# Freeze the wavlm model\n",
    "for param in phoneme_recognizer.wavlm.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "def write_to_csv(row):\n",
    "    with open(f'{OUTPUTS_DIR}/phonemes_training.csv', 'a') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(dataset.shuffle().select(range(50))):\n",
    "        inputs = get_audio_features(data)\n",
    "        log_probs = phoneme_recognizer(inputs)\n",
    "        split_phonemes = smart_split_coder(data[\"phoneme_sequence\"][0])\n",
    "        target = phoneme_recognizer.tokenize(split_phonemes)\n",
    "        loss = calculate_ctc_loss(log_probs[0], target.reshape([1, -1]))\n",
    "        linear_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        linear_optimizer.step()\n",
    "        write_to_csv(\n",
    "            [\n",
    "                increment, epoch, i, loss.item(),\n",
    "                \"\".join(phoneme_recognizer.classify_to_phonemes(log_probs)[0]),\n",
    "                \"\".join(split_phonemes)\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        increment += 1\n",
    "        torch.save(\n",
    "            phoneme_recognizer.phoneme_classifier.state_dict(),\n",
    "            f\"{MODEL_DIR}/phoneme_classifier_epoch_{epoch}_step_{i}_{increment}.pth\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5d7f10",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "\n",
    "We have a model roughly trained for phonemes.\n",
    "We want a binary classification though.\n",
    "We won't do that for now as it would be an end-to-end pipeline, defeating the purpose of the created pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
